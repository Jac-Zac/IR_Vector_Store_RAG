{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Store Implementation\n",
    "\n",
    "This is an implementation of a vector store that can leverage embedding models to create our vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "- Numpy\n",
    "- Pands\n",
    "\n",
    "##### Using files from:\n",
    "\n",
    "http://ir.dcs.gla.ac.uk/resources/test_collections/time/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index (Helper class)\n",
    "\n",
    "Implementation of an Helper class index which is going to be used in my vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self, dim = None):\n",
    "        self.dim = dim\n",
    "        \n",
    "        # Dictionary to store the vectors\n",
    "        self.stored_vectors = {}\n",
    "\n",
    "    def add_items(self, vectors, vectors_id) -> None:\n",
    "        \"\"\"\n",
    "        Update the indexing structure for the vector store\n",
    "        \"\"\"\n",
    "        for vector_id, vector in zip(vectors_id, vectors):\n",
    "            if vector.shape != (self.dim,):\n",
    "                raise ValueError(\"Vectors must have shape (dim,)\")\n",
    "            self.stored_vectors[vector_id] = vector\n",
    "\n",
    "    def knn_query(self, query_vector: np.ndarray, top_n: int = 5):\n",
    "        \"\"\"\n",
    "        Find the top n similar vectors to the query vector using cosine similarity.\n",
    "\n",
    "        Args:\n",
    "            query_vector (numpy.ndarray): The query vector.\n",
    "            top_n (int): The number of top similar vectors to return.\n",
    "\n",
    "        Returns:\n",
    "            A tuple of two numpy arrays: the first array contains the indices of the top n similar vectors,\n",
    "            and the second array contains the corresponding cosine similarity scores.\n",
    "        \"\"\"\n",
    "        similarities = [(index, self._cosine_similarity(query_vector, vector)) for index, vector in self.stored_vectors.items()]\n",
    "\n",
    "        # Sort base on the similarity and take the first top_n elements\n",
    "        # Then unpack it into indices and distances\n",
    "        top_n_indices, top_n_similarities = zip(*sorted(similarities, key=lambda x: x[1], reverse=True)[:top_n])\n",
    "\n",
    "        return top_n_indices, top_n_similarities\n",
    "        \n",
    "    def _cosine_similarity(self, query_vector, vector) -> float:\n",
    "        \"\"\"\n",
    "        Compute the similarity between two vectors\n",
    "\n",
    "        Args:\n",
    "            query_vector (numpy.ndarray): The query vector\n",
    "            vector (numpy.ndarray): The vector to compare\n",
    "\n",
    "        Returns:\n",
    "            The dot product of the vectors, normalized by the product of their norms\n",
    "        \"\"\"\n",
    "\n",
    "        dot_product = np.dot(query_vector, vector)\n",
    "        \n",
    "        query_vector_norm = np.linalg.norm(query_vector)\n",
    "        vector_norm = np.linalg.norm(vector)\n",
    "\n",
    "        # Return the similarity\n",
    "        return dot_product / (query_vector_norm * vector_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, vector_dimension = None, persist=True, persist_path=\"vector_store\", metric=\"cosine\"):\n",
    "\n",
    "        if vector_dimension is None:\n",
    "            print(\"You should pass the vector size\")\n",
    "\n",
    "        # Initialize our index our index\n",
    "        self.index = Index(dim=vector_dimension)\n",
    "\n",
    "        # Persistence\n",
    "        self.persist = persist\n",
    "        self.persist_path = persist_path\n",
    "        \n",
    "        self.vector_dimension = vector_dimension\n",
    "        \n",
    "        # A dictionary for indexing structure for retrieval\n",
    "        self.similarity_index = {}\n",
    "        \n",
    "        # Counter to then store the ids of vectors\n",
    "        self.id_counter : int = 0\n",
    "        \n",
    "        # Dictionary to store sentences corresponding to vectors\n",
    "        self.sentences = {}\n",
    "\n",
    "    def _load_vector_store(self):\n",
    "        index_file = os.path.join(self.persist_path, \"index.pkl\")\n",
    "        sentences_file = os.path.join(self.persist_path, \"sentences.pkl\")\n",
    "        \n",
    "        if not (os.path.exists(index_file) and os.path.exists(sentences_file)):\n",
    "            raise FileNotFoundError(\"Index and sentences files not found in the specified directory.\")\n",
    "\n",
    "        with open(index_file, \"rb\") as f:\n",
    "            self.index = pickle.load(f)\n",
    "        with open(sentences_file, \"rb\") as f:\n",
    "            self.sentences = pickle.load(f)\n",
    "\n",
    "        return self.index, self.sentences\n",
    "\n",
    "    def save_vector_store(self):\n",
    "        \"\"\"\n",
    "        Save the index and corresponding sentences\n",
    "        \"\"\"\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(self.persist_path, exist_ok=True)\n",
    "        \n",
    "        # Serialize and save the index\n",
    "        with open(os.path.join(self.persist_path, \"index.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.index, f)\n",
    "\n",
    "        # Serialize and save the sentences\n",
    "        with open(os.path.join(self.persist_path, \"sentences.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.sentences, f)\n",
    "    \n",
    "    def create_vector_store(self, new_sentence_vectors):\n",
    "        \"\"\"\n",
    "        Add vectors to the vector store\n",
    "\n",
    "        id: the unique id for the vector\n",
    "        vecotor: the vector to be added\n",
    "        \"\"\"\n",
    "        try:\n",
    "            vectors = []\n",
    "            ids = []\n",
    "            for sentence, vector in new_sentence_vectors.items():\n",
    "                # Append the new vector\n",
    "                vectors.append(vector)\n",
    "                # Assing a unique integer id to every vecotr\n",
    "                ids.append(self.id_counter)\n",
    "                # Store the sentence\n",
    "                self.sentences[self.id_counter] = sentence\n",
    "                # Incremeant the counter for the next vector\n",
    "                self.id_counter += 1\n",
    "\n",
    "            # Adding the items to the index\n",
    "            self.index.add_items(vectors, ids)\n",
    "    \n",
    "            if self.persist:       \n",
    "                 self.save_vector_store()\n",
    "                \n",
    "            print(\"Vector store created successfully\", end=\"\\n\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def update_vector_store(self, new_sentence_vectors):\n",
    "        \"\"\"\n",
    "        Update the existing vector store with new vectors\n",
    "\n",
    "        new_id_vectors: Dictionary containing new vectors to be added\n",
    "        persist_path: Path to the directory where the existing vector store is saved\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # load existing index and sentences\n",
    "            self.index, self.sentences = self._load_vector_store()\n",
    "\n",
    "            # Update the id counter\n",
    "            self.id_counter = max(self.sentences.keys()) + 1\n",
    "\n",
    "            # Add new vectors to the index and sentences\n",
    "            vectors = []\n",
    "            ids = []\n",
    "            for sentence, vector in new_sentence_vectors.items():\n",
    "                vectors.append(vector)\n",
    "                ids.append(self.id_counter)\n",
    "                self.sentences[self.id_counter] = sentence\n",
    "                self.id_counter += 1\n",
    "                \n",
    "            # Adding the vectors, idnex to the our index\n",
    "            self.index.add_items(vectors, ids)\n",
    "            \n",
    "            print(\"Vector store updated successfully\", end=\"\\n\\n\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def delete_vector_store(self) -> None:\n",
    "        try:\n",
    "            # Check if the directory exists\n",
    "            if os.path.exists(self.persist_path):\n",
    "                # Delete index and sentences files\n",
    "                os.remove(os.path.join(self.persist_path, \"index.pkl\"))\n",
    "                os.remove(os.path.join(self.persist_path, \"sentences.pkl\"))\n",
    "                print(\"Vector store deleted successfully\", end=\"\\n\\n\")\n",
    "            else:\n",
    "                print(\"Vector store does not exist\", end=\"\\n\\n\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def get_similar_vectors(self, query_vector, top_n=5) -> list:\n",
    "        \"\"\"\n",
    "        Find similar vectors to the query vector\n",
    "\n",
    "        Args:\n",
    "            query_vector (numpy.ndarray): The query vector to compare with the vecotr in the store\n",
    "            num_results (int): The number of similar vectors to return\n",
    "            persist_path: Path to the directory where the existing vector store is saved\n",
    "\n",
    "        Returns:\n",
    "            A list of tuples, each containing a vector id and its similarity to the query vector\n",
    "        \"\"\"\n",
    "        # load existing index and sentences\n",
    "        self.index, self.sentences = self._load_vector_store()\n",
    "        \n",
    "        result = []\n",
    "        labels, distances = self.index.knn_query(query_vector, top_n=top_n)\n",
    "\n",
    "        similar_vectors = [(self.sentences[label], distance) for label, distance in zip(labels, distances)]\n",
    "        \n",
    "        return similar_vectors\n",
    "        \"\"\" \n",
    "        for vector_id, vector in self.stored_vectors.items():\n",
    "            similarity = self._compute_similarity(query_vector, vector)\n",
    "            result.append((vector_id, similarity))\n",
    "            \n",
    "        # Sort by the similarity in descending order\n",
    "        result.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return the num_results most similar ones\n",
    "        return result[:num_results]\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of The vector store\n",
    "\n",
    "Using nomic embed for the demo and a custom index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully\n",
      "\n",
      "Similarity Vectors:\n",
      "- Sentence: The sleek, silver sports car raced down the winding mountain road, its engine roaring with power.\n",
      "  Similarity Score: 0.5229447484016418\n",
      "\n",
      "- Sentence: A family sedan cruised along the highway, its occupants singing along to their favorite songs on the radio.\n",
      "  Similarity Score: 0.5017635822296143\n",
      "\n",
      "- Sentence: A group of friends revved their engines, ready to hit the open road and leave the city behind.\n",
      "  Similarity Score: 0.4948986768722534\n",
      "\n",
      "- Sentence: The Harley-Davidson motorcycle rumbled to life, its deep, throaty growl announcing its presence on the road.\n",
      "  Similarity Score: 0.4918859899044037\n",
      "\n",
      "- Sentence: The sound of engines filled the air, a symphony of power and speed that echoed through the streets.\n",
      "  Similarity Score: 0.4788406491279602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the Embedding Model\n",
    "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
    "\n",
    "# Get data from csv\n",
    "data = pd.read_csv(\"data.csv\", delimiter=\";\")\n",
    "\n",
    "# Take 80% of the data to create the vector store, remaining 20% to update the vector store\n",
    "# To showcase the ability of updating the vector store\n",
    "data_1 = data.sample(frac=0.8, random_state=200)\n",
    "data_2 = data.drop(data_1.index)\n",
    "\n",
    "# Convert data to list\n",
    "# Instead of doing this I could decide to split documents in a smarter way with overlap or something\n",
    "\n",
    "data_1 = data_1[\"text\"].tolist()\n",
    "\n",
    "# Encode the data, have data and vector in dictionary, data keys, vector values\n",
    "vectors_1 = model.encode(data_1)\n",
    "\n",
    "# Get the vector dimension\n",
    "vector_dimension = len(vectors_1[0])\n",
    "\n",
    "# Create a dictionary with id and vectors\n",
    "new_sentence_vectors_1 = {data_1[i]: vectors_1[i] for i in range(len(data_1))}\n",
    "\n",
    "# Create a vector store. Select metric 'cosine' is the one I implemented (other possibility 'l1' or 'ip')\n",
    "vector_store = VectorStore(vector_dimension, metric=\"cosine\")\n",
    "\n",
    "# Create the vector store, set persist to True to save the vector store on disk\n",
    "# Implment persitence in the future\n",
    "vector_store.create_vector_store(new_sentence_vectors_1)\n",
    "\n",
    "# Query the vector store\n",
    "query = \"I want to buy a car\"\n",
    "query_vector = model.encode(query)\n",
    "similar_vectors = vector_store.get_similar_vectors(query_vector, top_n=5)\n",
    "\n",
    "# Visualize the most similar vectors\n",
    "print(\"Similarity Vectors:\")\n",
    "for sentence, similarity_score in similar_vectors:\n",
    "    print(f\"- Sentence: {sentence}\")\n",
    "    print(f\"  Similarity Score: {similarity_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding update of the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store updated successfully\n",
      "\n",
      "Similarity Vectors:\n",
      "- Sentence: And as the sun rises once again, the cycle begins anew, a testament to the beauty and resilience of life.\n",
      "  Similarity Score: 0.5324117541313171\n",
      "\n",
      "- Sentence: The Harley-Davidson motorcycle rumbled to life, its deep, throaty growl announcing its presence on the road.\n",
      "  Similarity Score: 0.521259605884552\n",
      "\n",
      "- Sentence: In the city, motorcyclists weaved through traffic with ease, their nimble machines darting between cars and buses.\n",
      "  Similarity Score: 0.48292413353919983\n",
      "\n",
      "- Sentence: A sleek, black sportbike hugged the curves of the mountain road, its rider leaning into each turn with precision.\n",
      "  Similarity Score: 0.4740353226661682\n",
      "\n",
      "- Sentence: Butterflies flit from flower to flower, their delicate wings carrying them on a dance of joy.\n",
      "  Similarity Score: 0.4396418035030365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update the vector store\n",
    "data_2 = data_2[\"text\"].tolist()\n",
    "vectors_2 = model.encode(data_2)\n",
    "new_sentence_vectors_2 = {data_2[i]: vectors_2[i] for i in range(len(data_2))}\n",
    "vector_store.update_vector_store(new_sentence_vectors_2)\n",
    "\n",
    "# Query the vector store\n",
    "query = \"I want to buy a cycle\"\n",
    "query_vector = model.encode(query)\n",
    "similar_vectors = vector_store.get_similar_vectors(query_vector, top_n=5)\n",
    "print(\"Similarity Vectors:\")\n",
    "for sentence, similarity_score in similar_vectors:\n",
    "    print(f\"- Sentence: {sentence}\")\n",
    "    print(f\"  Similarity Score: {similarity_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding persistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store deleted successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete saved vector store\n",
    "vector_store.delete_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the system on a set of test queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old way of using it\n",
    "\n",
    "Might be helpfull as a look up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should pass the vector size\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VectorStore' object has no attribute 'add_vector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Storing in VectorStore\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence, vector \u001b[38;5;129;01min\u001b[39;00m sentence_vectors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_vector\u001b[49m(sentence, vector)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Searching for Similarity\u001b[39;00m\n\u001b[1;32m     35\u001b[0m query_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMango is the best fruit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStore' object has no attribute 'add_vector'"
     ]
    }
   ],
   "source": [
    "# Create a VectorStore instance\n",
    "vector_store = VectorStore()\n",
    "\n",
    "# Define your sentences\n",
    "sentences = [\n",
    "    \"I eat mango\",\n",
    "    \"mango is my favorite fruit\",\n",
    "    \"mango, apple, oranges are fruits\",\n",
    "    \"fruits are good for health\",\n",
    "]\n",
    "\n",
    "# Tokenization and Vocabulary Creation\n",
    "vocabulary = set()\n",
    "for sentence in sentences:\n",
    "    tokens = sentence.lower().split()\n",
    "    vocabulary.update(tokens)\n",
    "\n",
    "# Assign unique indices to words in the vocabulary\n",
    "word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
    "\n",
    "# Vectorization\n",
    "sentence_vectors = {}\n",
    "for sentence in sentences:\n",
    "    tokens = sentence.lower().split()\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for token in tokens:\n",
    "        vector[word_to_index[token]] += 1\n",
    "    sentence_vectors[sentence] = vector\n",
    "\n",
    "# Storing in VectorStore\n",
    "for sentence, vector in sentence_vectors.items():\n",
    "    vector_store.add_vector(sentence, vector)\n",
    "\n",
    "# Searching for Similarity\n",
    "query_sentence = \"Mango is the best fruit\"\n",
    "query_vector = np.zeros(len(vocabulary))\n",
    "query_tokens = query_sentence.lower().split()\n",
    "for token in query_tokens:\n",
    "    if token in word_to_index:\n",
    "        query_vector[word_to_index[token]] += 1\n",
    "\n",
    "similar_sentences = vector_store.find_similar_vectors(query_vector, num_results=2)\n",
    "\n",
    "# Print similar sentences\n",
    "print(\"Query Sentence:\", query_sentence)\n",
    "print(\"Similar Sentences:\")\n",
    "for sentence, similarity in similar_sentences:\n",
    "    print(f\"{sentence}: Similarity = {similarity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv-kernel",
   "language": "python",
   "name": "local-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "139e7c84632f54486abb9d698f2a5412a324e85ce1b1331ea63d3255168fb27f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
